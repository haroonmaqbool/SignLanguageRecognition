# Sign Language Recognition System

## ğŸ“ Project Overview

**Course:** Introduction to Artificial Intelligence (COMP-360)  
**Institution:** Forman Christian College  
**Team:** Haroon, Saria, Azmeer  
**Instructor:** [Instructor Name]

This project implements a comprehensive **Sign Language Recognition System** using Deep Learning and Computer Vision techniques. The system can recognize American Sign Language (ASL) alphabet gestures and convert them into text, with support for both image upload and real-time webcam detection.

## ğŸš€ Features

- **Deep Learning Models**: CNN and LSTM architectures for gesture classification
- **Hand Landmark Extraction**: Using MediaPipe for robust hand detection
- **Real-time Detection**: Live webcam-based sign language recognition
- **Web Application**: Flask-based interface for easy interaction
- **Model Evaluation**: Comprehensive performance analysis and visualization
- **Multi-model Support**: Switch between CNN and LSTM models
- **Confidence Scoring**: Detailed prediction confidence and top predictions

## ğŸ“ Project Structure

```
Sign Language Recognition/
â”œâ”€â”€ preprocessing.py          # Data preprocessing and landmark extraction
â”œâ”€â”€ train_model.py           # CNN and LSTM model training
â”œâ”€â”€ evaluate_model.py        # Model evaluation and visualization
â”œâ”€â”€ realtime_detection.py    # Real-time webcam detection
â”œâ”€â”€ app.py                   # Flask web application
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ models/                 # Trained model files
â”‚   â”œâ”€â”€ cnn_final.h5
â”‚   â””â”€â”€ lstm_final.h5
â”œâ”€â”€ processed_data/         # Preprocessed dataset
â”‚   â”œâ”€â”€ X_train.npy
â”‚   â”œâ”€â”€ X_test.npy
â”‚   â”œâ”€â”€ y_train.npy
â”‚   â””â”€â”€ y_test.npy
â”œâ”€â”€ plots/                  # Generated visualizations
â”‚   â”œâ”€â”€ cnn_training_history.png
â”‚   â”œâ”€â”€ lstm_training_history.png
â”‚   â”œâ”€â”€ cnn_confusion_matrix.png
â”‚   â”œâ”€â”€ lstm_confusion_matrix.png
â”‚   â””â”€â”€ model_comparison.png
â”œâ”€â”€ reports/                # Evaluation reports
â”‚   â”œâ”€â”€ cnn_classification_report.txt
â”‚   â””â”€â”€ lstm_classification_report.txt
â””â”€â”€ templates/              # Web application templates
    â””â”€â”€ index.html
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites

- Python 3.7 or higher
- Webcam (for real-time detection)
- At least 4GB RAM (8GB recommended)
- GPU support (optional, for faster training)

### Step 1: Clone/Download Project

```bash
# If using git
git clone [repository-url]
cd sign-language-recognition

# Or download and extract the project files
```

### Step 2: Create Virtual Environment

```bash
# Create virtual environment
python -m venv sign_lang_env

# Activate virtual environment
# On Windows:
sign_lang_env\Scripts\activate
# On macOS/Linux:
source sign_lang_env/bin/activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 4: Run the Complete Pipeline

```bash
# 1. Preprocess the dataset
python preprocessing.py

# 2. Train the models
python train_model.py

# 3. Evaluate the models
python evaluate_model.py

# 4. Run real-time detection (optional)
python realtime_detection.py

# 5. Start the web application
python app.py
```

## ğŸ“Š Usage Guide

### 1. Data Preprocessing (`preprocessing.py`)

This module downloads the ASL alphabet dataset and extracts hand landmarks:

```bash
python preprocessing.py
```

**Features:**
- Downloads dataset from KaggleHub
- Extracts 21 hand landmarks per image
- Resizes images to 128Ã—128 pixels
- Splits data into train/test sets (80/20)
- Saves processed data as NumPy arrays

### 2. Model Training (`train_model.py`)

Trains both CNN and LSTM models for sign language classification:

```bash
python train_model.py
```

**Features:**
- Builds 1D CNN model for spatial feature extraction
- Builds LSTM model for temporal sequence processing
- Implements data augmentation and regularization
- Saves best and final model versions
- Generates training history plots

### 3. Model Evaluation (`evaluate_model.py`)

Comprehensive evaluation of trained models:

```bash
python evaluate_model.py
```

**Features:**
- Loads trained models and test data
- Generates confusion matrices
- Creates performance comparison charts
- Produces detailed classification reports
- Saves evaluation results and visualizations

### 4. Real-time Detection (`realtime_detection.py`)

Live webcam-based sign language recognition:

```bash
python realtime_detection.py
```

**Features:**
- Real-time webcam capture
- Live hand landmark extraction
- Instant gesture prediction
- Confidence score display
- Keyboard controls for interaction

**Controls:**
- `q`: Quit detection
- `h`: Toggle hand landmarks
- `s`: Save current frame
- `c`: Clear prediction history

### 5. Web Application (`app.py`)

Flask-based web interface for image upload and prediction:

```bash
python app.py
```

**Features:**
- Image upload and prediction
- Model selection (CNN/LSTM)
- Hand landmark visualization
- Confidence score display
- Responsive web interface

**Access:** Open your browser and go to `http://localhost:5000`

## ğŸ§  Technical Details

### Model Architecture

**CNN Model:**
- Input: 63-dimensional hand landmarks (21 points Ã— 3 coordinates)
- Conv1D layers with BatchNormalization and Dropout
- Global Average Pooling
- Dense layers with regularization
- Output: 26 classes (A-Z)

**LSTM Model:**
- Input: Reshaped landmarks (21, 3)
- LSTM layers with dropout
- Dense layers for classification
- Output: 26 classes (A-Z)

### Hand Landmark Extraction

- Uses MediaPipe Hands solution
- Extracts 21 hand landmarks per image
- Each landmark has (x, y, z) coordinates
- Robust to hand orientation and lighting

### Dataset

- **Source**: KaggleHub - ASL Alphabet Dataset
- **Classes**: 26 letters (A-Z)
- **Images**: Hand gesture photos
- **Preprocessing**: Resize to 128Ã—128, landmark extraction

## ğŸ“ˆ Performance Metrics

The system provides comprehensive evaluation metrics:

- **Accuracy**: Overall classification accuracy
- **Precision**: Per-class precision scores
- **Recall**: Per-class recall scores
- **F1-Score**: Harmonic mean of precision and recall
- **Confusion Matrix**: Detailed classification breakdown
- **Training History**: Loss and accuracy curves

## ğŸ”§ Troubleshooting

### Common Issues

1. **"No trained models found"**
   - Run `python train_model.py` first
   - Ensure models are saved in `models/` directory

2. **"Dataset not found"**
   - Run `python preprocessing.py` first
   - Check internet connection for KaggleHub download

3. **Webcam not working**
   - Ensure webcam is connected and not used by other applications
   - Check camera permissions

4. **Memory errors during training**
   - Reduce batch size in `train_model.py`
   - Use smaller model architectures
   - Close other applications

### Performance Optimization

- **GPU Support**: Install TensorFlow with GPU support for faster training
- **Batch Size**: Adjust batch size based on available memory
- **Model Complexity**: Reduce model size for faster inference

## ğŸ“š Dependencies

See `requirements.txt` for complete list of dependencies:

- **TensorFlow/Keras**: Deep learning framework
- **OpenCV**: Computer vision operations
- **MediaPipe**: Hand landmark extraction
- **NumPy**: Numerical computations
- **Scikit-learn**: Machine learning utilities
- **Matplotlib/Seaborn**: Visualization
- **Flask**: Web application framework

## ğŸ¯ Future Enhancements

- **PSL Support**: Add Pakistani Sign Language gestures
- **Word Recognition**: Extend to full words and phrases
- **Mobile App**: Develop mobile application
- **Real-time Translation**: Add text-to-speech functionality
- **Gesture Recording**: Allow users to record custom gestures

## ğŸ“„ License

This project is developed for educational purposes as part of the COMP-360 course at Forman Christian College.

## ğŸ‘¥ Team

- **Haroon** - [Role/Contribution]
- **Saria** - [Role/Contribution]  
- **Azmeer** - [Role/Contribution]

## ğŸ“ Support

For questions or issues, please contact the development team or refer to the course instructor.

---

**Note**: This project is designed for educational purposes and demonstrates the application of deep learning and computer vision techniques in sign language recognition.